{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1mNUWl8dfY5S",
    "outputId": "219b5ae7-4ce0-4041-91e2-6b7cb4cb2d48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting groq\n",
      "  Downloading groq-0.13.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.10.3)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.1)\n",
      "Downloading groq-0.13.0-py3-none-any.whl (108 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/108.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: groq\n",
      "Successfully installed groq-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install groq\n",
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZRAhIFP_EkeZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from groq import Groq\n",
    "from uuid import uuid4\n",
    "from langchain_core.documents import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVWVBK9JaPmA"
   },
   "outputs": [],
   "source": [
    "class ChatBot():\n",
    "\n",
    "  def __init__(self):\n",
    "    self.csvs = {\n",
    "    'CISSM': ['event_description'],\n",
    "    'HACKMAGEDDON': ['Description'],\n",
    "    'ICSSTRIVE': ['description'],\n",
    "    'KONBRIEFING': ['description'],\n",
    "    'TISAFE': ['attack_details', 'id'],\n",
    "    'WATERFALL': ['incident_summary', 'id']\n",
    "    }\n",
    "    self.k = 5\n",
    "    self.documents = []\n",
    "    self.model_name = 'sentence-transformers/all-mpnet-base-v2'\n",
    "    self.carga_documentos()\n",
    "    self.search_with_langchain_faiss()\n",
    "\n",
    "  def carga_documentos(self):\n",
    "    # Paso 2: Divide los csv en Documentos\n",
    "    for titulo_documento, columns in self.csvs.items():\n",
    "      df = pd.read_csv(f'data/{titulo_documento}_cleaned.csv')\n",
    "      df = df[columns]\n",
    "      if('id' not in columns):\n",
    "        df['id'] = df.index\n",
    "\n",
    "      for i, r in df.iterrows():\n",
    "        self.documents.append(\n",
    "            Document(\n",
    "                page_content = r[0],\n",
    "                metadata={\n",
    "                    \"source\":titulo_documento,\n",
    "                    \"id\":r['id']\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "\n",
    "  def search_with_langchain_faiss(self):\n",
    "    # Paso 1: Configura el modelo de embeddings\n",
    "    embeddings = HuggingFaceEmbeddings(model_name= self.model_name)\n",
    "\n",
    "    try:\n",
    "      print('Cargando base de datos')\n",
    "      self.faiss_index = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "    except:\n",
    "      print('Base de datos no encontrada, generamos base de datos')\n",
    "      # Paso 4: Carga los documentos en el índice FAISS usando from_documents\n",
    "      self.faiss_index = FAISS.from_documents(self.documents, embedding=embeddings)\n",
    "      self.faiss_index.save_local(\"faiss_index\")\n",
    "\n",
    "    print('Base de datos generada')\n",
    "\n",
    "  def busca_contexto(self, query):\n",
    "    # Paso 5: Realiza la búsqueda\n",
    "    results = self.faiss_index.similarity_search(query, k= self.k)\n",
    "\n",
    "    # Paso 6: Devuelve los resultados como texto\n",
    "    return [result.page_content for result in results]\n",
    "\n",
    "  def llamaResponse(self, query):\n",
    "    client = Groq(\n",
    "        # This is the default and can be omitted\n",
    "        api_key= 'Introduce your api key',\n",
    "    )\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "\n",
    "        messages=[\n",
    "\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "\n",
    "                \"content\": f\"\"\"\n",
    "\n",
    "                Eres un asistente diseñado para responder preguntas respecto a la ciberseguridad de la consultora de DeNexus.\n",
    "                Cuentas con la capacidad de responder a más preguntas pero siempre tienes que mencionar cual es tu objetivo principal antes de responder\n",
    "                cualquier otra cosa.\n",
    "                Ademas, si no sabes la respuesta a aquelllo que te preguntan, menciona el hecho de que no tienes registros al respecto.\n",
    "\n",
    "                Basa la respuesta en el siguiente contexto, si la respuesta a la pregunta no está en el contexto, responde con un: No lo sé\n",
    "                Contexto: {self.busca_contexto(query)}\n",
    "                \"\"\"\n",
    "            },\n",
    "\n",
    "            {\n",
    "\n",
    "                \"role\": \"user\",\n",
    "\n",
    "                \"content\": query,\n",
    "\n",
    "            }\n",
    "\n",
    "        ],\n",
    "\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "\n",
    "    )\n",
    "\n",
    "    return chat_completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qttnRxFPfS8a",
    "outputId": "cca68297-56ca-425e-9eb6-c9fb1e9a13f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-bc985ae370df>:29: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  page_content = r[0],\n",
      "<ipython-input-11-bc985ae370df>:29: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  page_content = r[0],\n",
      "<ipython-input-11-bc985ae370df>:29: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  page_content = r[0],\n",
      "<ipython-input-11-bc985ae370df>:29: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  page_content = r[0],\n",
      "<ipython-input-11-bc985ae370df>:29: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  page_content = r[0],\n",
      "<ipython-input-11-bc985ae370df>:29: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  page_content = r[0],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando base de datos\n"
     ]
    }
   ],
   "source": [
    "chat = ChatBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NpqEoo8vheM4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
